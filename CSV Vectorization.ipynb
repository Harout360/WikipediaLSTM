{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# File Generator\n",
    "Iterators over file sequenially. Only loads fixed sized amounts into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fileIter(source, valid_letters, encoding, num_chars):\n",
    "    with open(source, encoding='utf8') as file:\n",
    "        while True:\n",
    "            chunk = file.read(num_chars)\n",
    "            if chunk:\n",
    "                yield chunk\n",
    "            else:\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Set Program Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Input/Output files\n",
    "input_path      = 'wikitext-103-raw/wiki.test.clean'\n",
    "output_path     = 'wikitext-103-raw/wiki.test.vector'\n",
    "decoder_path    = 'wikitext-103-raw/wiki.test.decoder'\n",
    "vocab_path      = 'wikitext-103-raw/wiki.test.vocab'\n",
    "output_len_path = 'wikitext-103-raw/wiki.test.vector.len'\n",
    "\n",
    "# How many characters per line; For output file.\n",
    "# We read a large chunk of sentences from file, chunk should be as large as\n",
    "# possible. Too small and we waste time doing IO, too large and we waste time\n",
    "# writing page files.\n",
    "sentence_len = 50\n",
    "sentence_chunks = 100 * sentence_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Only include printable letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of possible letters:  95 \n",
      "\n",
      "{'$', 'o', 'C', 'l', '8', '1', 'd', '\\\\', 'j', \"'\", '+', 'Y', 'f', 'H', ']', 'n', 'L', 'u', '%', '<', 'A', 'i', 'c', 'q', '-', 'h', '0', '2', 'Z', '^', 'Q', ' ', '#', '>', 'a', '3', 'w', 'x', 'I', '\"', 'M', '}', 'v', 'O', 'S', '?', 'r', 'P', ',', 'k', '`', 'T', 'N', 'X', 'y', '4', 'U', 'p', 'g', '\\n', '5', '[', 'm', 't', '/', 'D', '=', '{', '.', '9', 'B', 's', ';', 'V', 'E', 'b', '&', '!', 'G', '6', '~', 'z', 'K', 'e', 'F', 'W', '|', ':', 'J', '_', '(', '7', ')', '*', 'R'}\n"
     ]
    }
   ],
   "source": [
    "valid_letters = set(string.printable)\n",
    "ignore_letters = set(['\\r','@','\\x0c','\\t','\\x0b'])\n",
    "valid_letters.difference_update(ignore_letters)\n",
    "print(\"Dimension of possible letters: \", len(valid_letters),'\\n')\n",
    "print(valid_letters)\n",
    "\n",
    "with open(vocab_path,'w') as vocab_file:\n",
    "    vocab_file.write(\"\".join(valid_letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Encode/Decode letters to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Enocder maps a letter -> integer\n",
    "encoder = dict((letter,position) for position, letter in enumerate(valid_letters))\n",
    "\n",
    "# Decoder maps an integer -> letter\n",
    "decoder = dict((value,key) for key,value in encoder.items())\n",
    "\n",
    "# Save dictionary to disk\n",
    "np.save(decoder_path, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convert Input by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk #: 0\n",
      "Processed chunk #: 100\n",
      "Processed chunk #: 200\n",
      "Finished writing CSV\n"
     ]
    }
   ],
   "source": [
    "# Get iterator over file\n",
    "file_iter = fileIter(input_path, encoding='utf8',valid_letters=valid_letters, num_chars=sentence_chunks)\n",
    "out = open(output_path,'w')\n",
    "\n",
    "# Write col name\n",
    "out.write('X;Y\\n')\n",
    "\n",
    "chunk_processed = 0\n",
    "row_count = 0\n",
    "ckpt = 100\n",
    "\n",
    "# Write data csv formatted\n",
    "for chunk in file_iter:\n",
    "    # Map letters to integers\n",
    "    chunk = [encoder[letter] for letter in chunk]\n",
    "    for start in range(0, len(chunk) - sentence_len, 10):\n",
    "        out.write(' '.join(map(str, chunk[start: start + sentence_len])))\n",
    "        out.write(';')\n",
    "        out.write(str(chunk[start + sentence_len]))\n",
    "        out.write('\\n')\n",
    "        row_count += 1\n",
    "    if chunk_processed % ckpt == 0:\n",
    "        print(\"Processed chunk #:\",chunk_processed)\n",
    "    chunk_processed += 1\n",
    "\n",
    "out.close()\n",
    "\n",
    "with open(output_len_path,'w') as file:\n",
    "    file.write(str(row_count))\n",
    "    \n",
    "print(\"Finished writing CSV\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
